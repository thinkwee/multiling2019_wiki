{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T10:14:07.035979Z",
     "start_time": "2019-07-05T10:14:06.565800Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from spacy import displacy\n",
    "import xml.etree.cElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多语言模型，仅识别实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T11:19:49.839794Z",
     "start_time": "2019-06-23T11:19:49.767953Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"xx_ent_wiki_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T11:19:50.489744Z",
     "start_time": "2019-06-23T11:19:50.487803Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T11:29:01.985545Z",
     "start_time": "2019-06-23T11:29:01.980475Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_lang(lang):\n",
    "    sentences = []\n",
    "    titles = []\n",
    "    count = {'ORG': 0, 'LOC': 0, 'PER': 0, 'MISC': 0, \"NoEnt\": 0}\n",
    "    total = 0\n",
    "    lines = 0\n",
    "    point = 0\n",
    "    with open(\"./WikiTrain19/raw_data/\" + lang + \".txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            title, sentence = line.split('\\t')\n",
    "            titles.append(title)\n",
    "            sentences.append(sentence[:-1])\n",
    "            lines += 1\n",
    "            if lines == 1000:\n",
    "                break\n",
    "    l = len(sentences)\n",
    "    doc_raw = ' . '.join(sentences)\n",
    "    doc = nlp(doc_raw)\n",
    "    for idx, sent in enumerate(doc.sents):\n",
    "        flag = False\n",
    "        if idx == l:\n",
    "            break\n",
    "        for ent in sent.ents:\n",
    "            if titles[idx].lower() in ent.text.lower():\n",
    "                flag = True\n",
    "                count[ent.label_] += 1\n",
    "                point += 1\n",
    "            break\n",
    "        if not flag:\n",
    "            count[\"NoEnt\"] += 1\n",
    "        total += 1\n",
    "    print(lang)\n",
    "    for key in count:\n",
    "        print(key, count[key])\n",
    "    print(point/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T11:29:10.560301Z",
     "start_time": "2019-06-23T11:29:02.175437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "en\n",
      "ORG 12\n",
      "LOC 43\n",
      "PER 33\n",
      "MISC 17\n",
      "NoEnt 895\n",
      "0.105\n",
      "de\n",
      "de\n",
      "ORG 31\n",
      "LOC 264\n",
      "PER 153\n",
      "MISC 32\n",
      "NoEnt 520\n",
      "0.48\n",
      "es\n",
      "es\n",
      "ORG 2\n",
      "LOC 9\n",
      "PER 2\n",
      "MISC 0\n",
      "NoEnt 987\n",
      "0.013\n",
      "fr\n",
      "fr\n",
      "ORG 1\n",
      "LOC 13\n",
      "PER 14\n",
      "MISC 1\n",
      "NoEnt 44\n",
      "0.3972602739726027\n",
      "it\n",
      "it\n",
      "ORG 2\n",
      "LOC 1\n",
      "PER 4\n",
      "MISC 1\n",
      "NoEnt 365\n",
      "0.021447721179624665\n",
      "pt\n",
      "pt\n",
      "ORG 0\n",
      "LOC 25\n",
      "PER 3\n",
      "MISC 10\n",
      "NoEnt 56\n",
      "0.40425531914893614\n",
      "ru\n",
      "ru\n",
      "ORG 0\n",
      "LOC 4\n",
      "PER 0\n",
      "MISC 4\n",
      "NoEnt 24\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "for lang in [\"en\", \"de\", \"es\", \"fr\", \"it\", \"pt\", \"ru\"]:\n",
    "    print(lang)\n",
    "    check_lang(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单语言模型，根据依存分析找出主语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T09:26:48.934374Z",
     "start_time": "2019-06-22T09:24:40.617465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "0.5067229106248352\n",
      "de\n",
      "0.4895833333333333\n",
      "fr\n",
      "0.4\n",
      "es\n",
      "0.451171875\n",
      "el\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "for lang, model in zip([\"en\", \"de\", \"fr\", \"es\", \"el\"], [\n",
    "        \"en_core_web_sm\", \"de_core_news_sm\", \"fr_core_news_sm\",\n",
    "        \"es_core_news_sm\", \"el_core_news_sm\"\n",
    "]):\n",
    "    print(lang)\n",
    "    nlp = spacy.load(model)\n",
    "    count = 0\n",
    "    right = 0\n",
    "    for f in os.listdir(\"./WikiTrain19/full/\" + lang):\n",
    "        tree = ET.ElementTree(file=\"./WikiTrain19/full/\" + lang + \"/\" + f)\n",
    "        root = tree.getroot()\n",
    "        title = root[0].text.lower()\n",
    "        for sentence in root[1][0].text.split(\". \"):\n",
    "            doc = nlp(sentence)\n",
    "            for token in doc:\n",
    "                if token.dep_ == \"ROOT\":\n",
    "                    root = token\n",
    "            for chunk in doc.noun_chunks:\n",
    "                if chunk.root.head == root:\n",
    "                    result = chunk.text\n",
    "                    break\n",
    "            if title in result.lower():\n",
    "                #                 print(sentence)\n",
    "                #                 print(title + \" | \" + result.lower())\n",
    "                right += 1\n",
    "        count += 1\n",
    "    print(right / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-22T09:24:26.377054Z",
     "start_time": "2019-06-22T09:24:22.031813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pt]\n",
      "0.43333333333333335\n",
      "[it]\n",
      "0.5234657039711191\n",
      "[nl]\n",
      "0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "for lang, model in zip(\n",
    "    [\"pt\", \"it\", \"nl\"],\n",
    "    [\"pt_core_news_sm\", \"it_core_news_sm\", \"nl_core_news_sm\"]):\n",
    "    print(\"[\" + lang + \"]\")\n",
    "    nlp = spacy.load(model)\n",
    "    count = 0\n",
    "    right = 0\n",
    "    for f in os.listdir(\"./WikiTrain19/full/\" + lang):\n",
    "        tree = ET.ElementTree(file=\"./WikiTrain19/full/\" + lang + \"/\" + f)\n",
    "        root = tree.getroot()\n",
    "        title = root[0].text.lower()\n",
    "        for sentence in root[1][0].text.split(\". \"):\n",
    "            doc = nlp(sentence)\n",
    "            for token in doc:\n",
    "                if token.dep_ == \"ROOT\":\n",
    "                    root = token\n",
    "            result = \"\"\n",
    "            for ent in doc.ents:\n",
    "                result = ent.text\n",
    "                break\n",
    "            if title in result.lower():\n",
    "                #                 print(sentence)\n",
    "                #                 print(title + \" | \" + result.lower())\n",
    "                right += 1\n",
    "        count += 1\n",
    "    print(right / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T10:18:29.859022Z",
     "start_time": "2019-07-05T10:18:29.851989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'section' at 0x7f5cd44f34f8>\n",
      "<Element 'header' at 0x7f5cd44f34a8>\n",
      "<Element 'p' at 0x7f5cd44f3458>\n",
      "<Element 'p' at 0x7f5cd44f3408>\n",
      "<Element 'p' at 0x7f5cd44f3098>\n",
      "\n",
      "<Element 'section' at 0x7f5cd44f31d8>\n",
      "<Element 'header' at 0x7f5cd44f3188>\n",
      "<Element 'p' at 0x7f5cd44f3138>\n",
      "<Element 'p' at 0x7f5cd44f30e8>\n",
      "<Element 'p' at 0x7f5cd44f3048>\n",
      "\n",
      "<Element 'section' at 0x7f5cd41cdbd8>\n",
      "<Element 'header' at 0x7f5cd41cdae8>\n",
      "<Element 'p' at 0x7f5cd41cda98>\n",
      "<Element 'p' at 0x7f5cd41cd728>\n",
      "<Element 'p' at 0x7f5cd41cd778>\n",
      "<Element 'p' at 0x7f5cd41cd9f8>\n",
      "<Element 'p' at 0x7f5cd41cda48>\n",
      "<Element 'p' at 0x7f5cd41cd8b8>\n",
      "<Element 'section' at 0x7f5cd41cdc28>\n",
      "<Element 'section' at 0x7f5cd41cdf48>\n",
      "<Element 'section' at 0x7f5cd41e4f98>\n",
      "\n",
      "<Element 'section' at 0x7f5cd44cf228>\n",
      "<Element 'header' at 0x7f5cd44cf278>\n",
      "<Element 'section' at 0x7f5cd44cf2c8>\n",
      "<Element 'section' at 0x7f5cd44cf4f8>\n",
      "<Element 'section' at 0x7f5cd44cf5e8>\n",
      "<Element 'section' at 0x7f5cd44cf728>\n",
      "<Element 'section' at 0x7f5cd44cf868>\n",
      "\n",
      "<Element 'section' at 0x7f5cd44cf9f8>\n",
      "<Element 'header' at 0x7f5cd44cfa48>\n",
      "<Element 'section' at 0x7f5cd44cfa98>\n",
      "<Element 'section' at 0x7f5cd44cfbd8>\n",
      "<Element 'section' at 0x7f5cd44cfdb8>\n",
      "\n",
      "<Element 'section' at 0x7f5cd44cfea8>\n",
      "<Element 'header' at 0x7f5cd44cfef8>\n",
      "<Element 'p' at 0x7f5cd44cff48>\n",
      "<Element 'p' at 0x7f5cd44cff98>\n",
      "<Element 'p' at 0x7f5cd44e7048>\n",
      "<Element 'section' at 0x7f5cd44e7098>\n",
      "<Element 'section' at 0x7f5cd44e7188>\n",
      "<Element 'section' at 0x7f5cd44e7318>\n",
      "\n",
      "<Element 'section' at 0x7f5cd44e77c8>\n",
      "<Element 'header' at 0x7f5cd44e7818>\n",
      "<Element 'p' at 0x7f5cd44e7868>\n",
      "<Element 'p' at 0x7f5cd44e78b8>\n",
      "<Element 'p' at 0x7f5cd44e7908>\n",
      "<Element 'section' at 0x7f5cd44e7958>\n",
      "<Element 'section' at 0x7f5cd44e7e08>\n",
      "\n",
      "<Element 'section' at 0x7f5cd44e7f98>\n",
      "<Element 'header' at 0x7f5cd44f6048>\n",
      "<Element 'p' at 0x7f5cd44f6098>\n",
      "<Element 'p' at 0x7f5cd44f60e8>\n",
      "<Element 'p' at 0x7f5cd44f6138>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(\"./WikiTrain19/full/en\"):\n",
    "    tree = ET.ElementTree(file=\"./WikiTrain19/full/en/\" + f)\n",
    "    root = tree.getroot()\n",
    "    for section in root[2]:\n",
    "        print(section)\n",
    "        for t in section:\n",
    "            print(t)\n",
    "        print()\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
