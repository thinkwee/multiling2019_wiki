{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:36:52.523452Z",
     "start_time": "2019-07-11T12:36:52.287341Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "import xml.etree.cElementTree as ET\n",
    "import xml.dom.minidom\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:36:53.672042Z",
     "start_time": "2019-07-11T12:36:53.213404Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parser for xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:36:55.035122Z",
     "start_time": "2019-07-11T12:36:55.016723Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParseXML_2019(object):\n",
    "    def __init__(self):\n",
    "        self.title = []\n",
    "        self.text = []\n",
    "        self.all_content = []\n",
    "        self.header_length = []\n",
    "        self.entry = \"\"\n",
    "        self.entry_node = None\n",
    "        self.header_node = []\n",
    "        self.tree = None\n",
    "\n",
    "    def __get_values(self, root):\n",
    "        node_list = []\n",
    "        for node in root:\n",
    "            node_list.append(node)\n",
    "        l = len(node_list)\n",
    "        i = 0\n",
    "        while i<l:           \n",
    "            if node_list[i].tag == \"section\":\n",
    "                self.__get_values(node_list[i])\n",
    "            elif node_list[i].tag == \"header\":\n",
    "                self.title.append(node_list[i].text)\n",
    "                self.all_content.append(node_list[i].text + \" #header#\")\n",
    "            elif node_list[i].tag == \"p\":\n",
    "                if node_list[i-1].tag == \"header\":\n",
    "                    self.header_length.append(int(node_list[i-1].text))\n",
    "                    self.header_node.append(node_list[i-1])\n",
    "                text = \"\"\n",
    "                while node_list[i].tag==\"p\":\n",
    "                    text += node_list[i].text\n",
    "                    i += 1\n",
    "                    if i>=l:\n",
    "                        break\n",
    "                self.text.append(text)\n",
    "                self.all_content.append(text)\n",
    "            i += 1\n",
    "            if i>=l:\n",
    "                break\n",
    "\n",
    "    def __get_length(self, root):\n",
    "        for node in root:\n",
    "            if node.tag == \"p\":\n",
    "                self.summary += (node.text)\n",
    "                \n",
    "    def parse(self, xml_path):\n",
    "        self.title = []\n",
    "        self.text = []\n",
    "        self.all_content = []\n",
    "        self.summary = []\n",
    "        tree = ET.ElementTree(file=xml_path)\n",
    "        self.tree = tree\n",
    "        for node in tree.getroot():\n",
    "            if node.tag == \"title\":\n",
    "                self.entry = node.text\n",
    "                self.entry_node = node\n",
    "            elif node.tag == \"body\":\n",
    "                self.__get_values(node)\n",
    "            if node.tag == \"summary\":\n",
    "                self.__get_length(node)\n",
    "        #print self.summary_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:00.322717Z",
     "start_time": "2019-07-11T12:37:00.305791Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/lyn/lw/multiling2019/multiling2019_wiki/WikiTrain19/tagged_data/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:00.919797Z",
     "start_time": "2019-07-11T12:37:00.850776Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.is_available(), torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:01.378224Z",
     "start_time": "2019-07-11T12:37:01.346282Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules.models.bert_models import BertBiLSTMAttnNMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:01.957482Z",
     "start_time": "2019-07-11T12:37:01.921615Z"
    }
   },
   "outputs": [],
   "source": [
    "init_checkpoint_pt = os.path.join(\n",
    "    \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/multi_cased_L-12_H-768_A-12/\",\n",
    "    \"pytorch_model.bin\")\n",
    "bert_config_file = os.path.join(\n",
    "    \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/multi_cased_L-12_H-768_A-12/\",\n",
    "    \"bert_config.json\")\n",
    "vocab_file = os.path.join(\n",
    "    \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/multi_cased_L-12_H-768_A-12/\",\n",
    "    \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:05.274659Z",
     "start_time": "2019-07-11T12:37:02.493039Z"
    }
   },
   "outputs": [],
   "source": [
    "# train a new model\n",
    "model = BertBiLSTMAttnNMT.create(6,\n",
    "                                 bert_config_file,\n",
    "                                 init_checkpoint_pt,\n",
    "                                 enc_hidden_dim=256,\n",
    "                                 dec_hidden_dim=256,\n",
    "                                 dec_embedding_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:07.754586Z",
     "start_time": "2019-07-11T12:37:07.453870Z"
    }
   },
   "outputs": [],
   "source": [
    "# load a model\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/models/multiling-2019/BertBiLSTMAttnNMT.cpt\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make dataset(only use testset) and load learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:08.487822Z",
     "start_time": "2019-07-11T12:37:08.473831Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules import BertNerData as NerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:08.929181Z",
     "start_time": "2019-07-11T12:37:08.899302Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = data_path + \"train.csv\"\n",
    "valid_path = data_path + \"valid.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:17.436675Z",
     "start_time": "2019-07-11T12:37:09.299302Z"
    }
   },
   "outputs": [],
   "source": [
    "data = NerData.create(train_path, valid_path, vocab_file, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:17.449316Z",
     "start_time": "2019-07-11T12:37:17.437821Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules import NerLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:17.462477Z",
     "start_time": "2019-07-11T12:37:17.450941Z"
    }
   },
   "outputs": [],
   "source": [
    "sup_labels = ['B_MISC', 'I_MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:19.880858Z",
     "start_time": "2019-07-11T12:37:19.869895Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:20.393713Z",
     "start_time": "2019-07-11T12:37:20.354104Z"
    }
   },
   "outputs": [],
   "source": [
    "learner = NerLearner(\n",
    "    model,\n",
    "    data,\n",
    "    best_model_path=\n",
    "    \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/models/multiling-2019/BertBiLSTMAttnNMT.cpt\",\n",
    "    lr=0.01,\n",
    "    clip=1.0,\n",
    "    sup_labels=sup_labels,\n",
    "    t_total=num_epochs * len(data.train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make title test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:22.882094Z",
     "start_time": "2019-07-11T12:37:22.865373Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_test_csv(path,para=None):\n",
    "    if para==None:\n",
    "        para = open(path[:-4] + \".txt\", \"r\").read()\n",
    "    data_tag = []\n",
    "    with open(path[:-4] + \".csv\", 'w', encoding='utf-8', newline='') as f:\n",
    "        f_csv = csv.writer(f)\n",
    "        if \"zh\" in path:\n",
    "            for line in para.split(\"。\"):\n",
    "                l = len(line)\n",
    "                line = str(line)\n",
    "                #                 tag = [\"O\" for w in range(l)]\n",
    "                data_tag.append([\" \".join([\"O\" for w in line]), \" \".join([w for w in line])])\n",
    "        else:\n",
    "            for line in para.split(\". \"):\n",
    "                l = len(line.split(\" \"))\n",
    "                tag = [\"O\" for _ in range(l)]\n",
    "                data_tag.append([\" \".join(tag), line])\n",
    "        f_csv.writerows(data_tag)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pick title based on tagged results and choose one that best suits length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:47:53.580839Z",
     "start_time": "2019-07-11T12:47:53.565564Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_result(f, preds, title_len, zh):\n",
    "    result = \"\"\n",
    "    max_dis = 32768\n",
    "    best_sentence = \"\"\n",
    "    for sentence, pred in zip(f, preds):\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] == 'B_MISC':\n",
    "                answer = sentence.bert_tokens[i]\n",
    "                for j in range(i + 1, len(pred)):\n",
    "                    if pred[j] == 'I_MISC':\n",
    "                        answer += \" \" + sentence.bert_tokens[j]\n",
    "                    else:\n",
    "                        break\n",
    "                len_answer = len(answer)\n",
    "                if abs(len_answer - title_len) < max_dis:\n",
    "                    max_dis = abs(len_answer - title_len)\n",
    "                    best_sentence = sentence\n",
    "                    if zh:\n",
    "                        result = \"\".join(answer.split(\" \"))\n",
    "                    else:\n",
    "                        result = answer\n",
    "#     if result != \"\":\n",
    "#         if zh:\n",
    "#             print(\"\".join(best_sentence.bert_tokens))\n",
    "#         else:\n",
    "#             print(\" \".join(best_sentence.bert_tokens))\n",
    "    print(\"@@\" + result + \"@@\",end=' ')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choose a language and set relative paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:38:28.069473Z",
     "start_time": "2019-07-11T12:38:28.057735Z"
    }
   },
   "outputs": [],
   "source": [
    "path_result = \"/home/lyn/lw/multiling2019/multiling2019_wiki/WikiTrain19/test/MultiLing2019-Summary-2length/result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:38:28.547501Z",
     "start_time": "2019-07-11T12:38:28.513270Z"
    }
   },
   "outputs": [],
   "source": [
    "path_head = \"/home/lyn/lw/multiling2019/multiling2019_wiki/WikiTrain19/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:38:35.896037Z",
     "start_time": "2019-07-11T12:38:35.885226Z"
    }
   },
   "outputs": [],
   "source": [
    "lan_path = path_head + \"MultiLing2019-Summary-2length/2019.07.06-10.54.47-SentenceVec/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:51:00.430749Z",
     "start_time": "2019-07-11T12:51:00.417094Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_title(test_path, original_path, zh, language):\n",
    "    for article in os.listdir(test_path):\n",
    "        if \"csv\" in article and \"subtitle\" not in article:\n",
    "#             print(article)\n",
    "            tree = ET.ElementTree(file=original_path + article[:-4] + \".xml\")\n",
    "            root = tree.getroot()\n",
    "            title_len = int(root[0].text.lower())\n",
    "#             print(title_len)\n",
    "            dl, f = get_bert_data_loader_for_predict(test_path + article, learner)\n",
    "            preds = learner.predict(dl)\n",
    "            parser = ParseXML_2019()        \n",
    "            parser.parse(original_path + article[:-4] + \".xml\")\n",
    "            parser.entry_node.text = show_result(f, preds, title_len, zh)\n",
    "            parser.tree.write(path_result + language + \"/\" + article[:-4] + \".xml\", encoding=\"utf-8\",xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:52:51.361828Z",
     "start_time": "2019-07-11T12:52:51.345400Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_subtitle(test_path, original_path, zh, language):\n",
    "    for file_name in os.listdir(original_path):\n",
    "        if \"xml\" in file_name:\n",
    "            print(file_name)\n",
    "            parser = ParseXML_2019()     \n",
    "            try:\n",
    "                parser.parse(path_result + language + \"/\" + file_name[:-4] + \".xml\")\n",
    "        #         print(len(parser.header_node),len(parser.header_length),len(parser.text))\n",
    "                for length,text,header in zip(parser.header_length, parser.text, parser.header_node):\n",
    "                    tmp_csv_for_subtitle = test_path + str(file_name[:-4]) + \"_subtitle\"\n",
    "                    make_test_csv(tmp_csv_for_subtitle + \".xml\", text) \n",
    "                    try:\n",
    "                        dl, f = get_bert_data_loader_for_predict(tmp_csv_for_subtitle + \".csv\", learner)\n",
    "                    except RuntimeError:\n",
    "                        print(file_name)\n",
    "                    preds = learner.predict(dl)\n",
    "                    header.text = show_result(f, preds, length, zh)\n",
    "                parser.tree.write(path_result + language + \"/\" + file_name[:-4] + \".xml\", encoding=\"utf-8\",xml_declaration=True)\n",
    "            except FileNotFoundError:\n",
    "                print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:29:23.526307Z",
     "start_time": "2019-07-11T13:29:12.216323Z"
    }
   },
   "outputs": [],
   "source": [
    "for language in os.listdir(lan_path):\n",
    "    if \"txt\" not in language and \"ja\" in language:\n",
    "        print(\"\\n-------------------------\" + language + \"----------------------------\\n\")\n",
    "        test_path = path_head + \"MultiLing2019-Summary-2length/2019.07.06-10.54.47-SentenceVec/\" + language + \"/systems/\"\n",
    "        original_path = path_head + \"WikiTest19/clipped/\" + language + \"/\"\n",
    "        if \"zh\" in test_path or \"ja\" in test_path:\n",
    "            zh = True\n",
    "        else:\n",
    "            zh = False\n",
    "        for idx, f in enumerate(os.listdir(test_path)):\n",
    "            if \"txt\" in f:\n",
    "#                 print(idx, f)\n",
    "                make_test_csv(test_path + f)\n",
    "        make_title(test_path, original_path, zh, language)\n",
    "        make_subtitle(test_path, original_path, zh, language)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T13:27:03.941020Z",
     "start_time": "2019-07-09T13:27:03.905552Z"
    }
   },
   "outputs": [],
   "source": [
    "language = \"zh\"\n",
    "\n",
    "test_path = path_head + \"MultiLing2019-Summary-2length/2019.07.06-10.54.47-SentenceVec/\" + language + \"/systems/\"\n",
    "original_path = path_head + \"WikiTest19/clipped/\" + language + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make test csv for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T13:27:04.815467Z",
     "start_time": "2019-07-09T13:27:04.769681Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, f in enumerate(os.listdir(test_path)):\n",
    "    if \"txt\" in f:\n",
    "        print(idx, f)\n",
    "        make_test_csv(test_path + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show results for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T13:30:26.374728Z",
     "start_time": "2019-07-09T13:30:24.163834Z"
    }
   },
   "outputs": [],
   "source": [
    "if \"zh\" in test_path:\n",
    "    zh = True\n",
    "else:\n",
    "    zh = False\n",
    "for article in os.listdir(test_path):\n",
    "    if \"csv\" in article and \"subtitle\" not in article:\n",
    "        print(article)\n",
    "        tree = ET.ElementTree(file=original_path + article[:-4] + \".xml\")\n",
    "        root = tree.getroot()\n",
    "        title_len = int(root[0].text.lower())\n",
    "        print(title_len)\n",
    "        dl, f = get_bert_data_loader_for_predict(test_path + article, learner)\n",
    "        preds = learner.predict(dl)\n",
    "        parser = ParseXML_2019()        \n",
    "        parser.parse(original_path + article[:-4] + \".xml\")\n",
    "        parser.entry_node.text = show_result(f, preds, title_len, zh)\n",
    "        parser.tree.write(test_path + article[:-4] + \"_result.xml\", encoding=\"utf-8\",xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make test csv for subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T13:30:45.053896Z",
     "start_time": "2019-07-09T13:30:28.728010Z"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in os.listdir(original_path):\n",
    "    if \"xml\" in file_name:\n",
    "        print(file_name)\n",
    "        parser = ParseXML_2019()        \n",
    "        parser.parse(test_path + file_name[:-4] + \"_result.xml\")\n",
    "#         print(len(parser.header_node),len(parser.header_length),len(parser.text))\n",
    "        for length,text,header in zip(parser.header_length, parser.text, parser.header_node):\n",
    "            tmp_csv_for_subtitle = test_path + str(file_name[:-4]) + \"_subtitle\"\n",
    "            make_test_csv(tmp_csv_for_subtitle + \".xml\", text) \n",
    "            dl, f = get_bert_data_loader_for_predict(tmp_csv_for_subtitle + \".csv\", learner)\n",
    "            preds = learner.predict(dl)\n",
    "            header.text = show_result(f, preds, length, zh)\n",
    "        parser.tree.write(test_path + file_name[:-4] + \"_result.xml\", encoding=\"utf-8\",xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
