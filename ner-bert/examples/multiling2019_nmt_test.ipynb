{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:36:52.523452Z",
     "start_time": "2019-07-11T12:36:52.287341Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "import xml.etree.cElementTree as ET\n",
    "import xml.dom.minidom\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:36:53.672042Z",
     "start_time": "2019-07-11T12:36:53.213404Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules.data.bert_data import get_bert_data_loader_for_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parser for xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:36:55.035122Z",
     "start_time": "2019-07-11T12:36:55.016723Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParseXML_2019(object):\n",
    "    def __init__(self):\n",
    "        self.title = []\n",
    "        self.text = []\n",
    "        self.all_content = []\n",
    "        self.header_length = []\n",
    "        self.entry = \"\"\n",
    "        self.entry_node = None\n",
    "        self.header_node = []\n",
    "        self.tree = None\n",
    "\n",
    "    def __get_values(self, root):\n",
    "        node_list = []\n",
    "        for node in root:\n",
    "            node_list.append(node)\n",
    "        l = len(node_list)\n",
    "        i = 0\n",
    "        while i<l:           \n",
    "            if node_list[i].tag == \"section\":\n",
    "                self.__get_values(node_list[i])\n",
    "            elif node_list[i].tag == \"header\":\n",
    "                self.title.append(node_list[i].text)\n",
    "                self.all_content.append(node_list[i].text + \" #header#\")\n",
    "            elif node_list[i].tag == \"p\":\n",
    "                if node_list[i-1].tag == \"header\":\n",
    "                    self.header_length.append(int(node_list[i-1].text))\n",
    "                    self.header_node.append(node_list[i-1])\n",
    "                text = \"\"\n",
    "                while node_list[i].tag==\"p\":\n",
    "                    text += node_list[i].text\n",
    "                    i += 1\n",
    "                    if i>=l:\n",
    "                        break\n",
    "                self.text.append(text)\n",
    "                self.all_content.append(text)\n",
    "            i += 1\n",
    "            if i>=l:\n",
    "                break\n",
    "\n",
    "    def __get_length(self, root):\n",
    "        for node in root:\n",
    "            if node.tag == \"p\":\n",
    "                self.summary += (node.text)\n",
    "                \n",
    "    def parse(self, xml_path):\n",
    "        self.title = []\n",
    "        self.text = []\n",
    "        self.all_content = []\n",
    "        self.summary = []\n",
    "        tree = ET.ElementTree(file=xml_path)\n",
    "        self.tree = tree\n",
    "        for node in tree.getroot():\n",
    "            if node.tag == \"title\":\n",
    "                self.entry = node.text\n",
    "                self.entry_node = node\n",
    "            elif node.tag == \"body\":\n",
    "                self.__get_values(node)\n",
    "            if node.tag == \"summary\":\n",
    "                self.__get_length(node)\n",
    "        #print self.summary_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:00.322717Z",
     "start_time": "2019-07-11T12:37:00.305791Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/lyn/lw/multiling2019/multiling2019_wiki/WikiTrain19/tagged_data/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:00.919797Z",
     "start_time": "2019-07-11T12:37:00.850776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.is_available(), torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:01.378224Z",
     "start_time": "2019-07-11T12:37:01.346282Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules.models.bert_models import BertBiLSTMAttnNMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:01.957482Z",
     "start_time": "2019-07-11T12:37:01.921615Z"
    }
   },
   "outputs": [],
   "source": [
    "init_checkpoint_pt = os.path.join(\n",
    "    \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/multi_cased_L-12_H-768_A-12/\",\n",
    "    \"pytorch_model.bin\")\n",
    "bert_config_file = os.path.join(\n",
    "    \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/multi_cased_L-12_H-768_A-12/\",\n",
    "    \"bert_config.json\")\n",
    "vocab_file = os.path.join(\n",
    "    \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/multi_cased_L-12_H-768_A-12/\",\n",
    "    \"vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:05.274659Z",
     "start_time": "2019-07-11T12:37:02.493039Z"
    }
   },
   "outputs": [],
   "source": [
    "# train a new model\n",
    "model = BertBiLSTMAttnNMT.create(6,\n",
    "                                 bert_config_file,\n",
    "                                 init_checkpoint_pt,\n",
    "                                 enc_hidden_dim=256,\n",
    "                                 dec_hidden_dim=256,\n",
    "                                 dec_embedding_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:07.754586Z",
     "start_time": "2019-07-11T12:37:07.453870Z"
    }
   },
   "outputs": [],
   "source": [
    "# load a model\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/models/multiling-2019/BertBiLSTMAttnNMT.cpt\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make dataset(only use testset) and load learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:08.487822Z",
     "start_time": "2019-07-11T12:37:08.473831Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules import BertNerData as NerData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:08.929181Z",
     "start_time": "2019-07-11T12:37:08.899302Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = data_path + \"train.csv\"\n",
    "valid_path = data_path + \"valid.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:17.436675Z",
     "start_time": "2019-07-11T12:37:09.299302Z"
    }
   },
   "outputs": [],
   "source": [
    "data = NerData.create(train_path, valid_path, vocab_file, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:17.449316Z",
     "start_time": "2019-07-11T12:37:17.437821Z"
    }
   },
   "outputs": [],
   "source": [
    "from modules import NerLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:17.462477Z",
     "start_time": "2019-07-11T12:37:17.450941Z"
    }
   },
   "outputs": [],
   "source": [
    "sup_labels = ['B_MISC', 'I_MISC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:19.880858Z",
     "start_time": "2019-07-11T12:37:19.869895Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:20.393713Z",
     "start_time": "2019-07-11T12:37:20.354104Z"
    }
   },
   "outputs": [],
   "source": [
    "learner = NerLearner(\n",
    "    model,\n",
    "    data,\n",
    "    best_model_path=\n",
    "    \"/home/lyn/lw/multiling2019/multiling2019_wiki/ner-bert/datadrive/models/multiling-2019/BertBiLSTMAttnNMT.cpt\",\n",
    "    lr=0.01,\n",
    "    clip=1.0,\n",
    "    sup_labels=sup_labels,\n",
    "    t_total=num_epochs * len(data.train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make title test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:37:22.882094Z",
     "start_time": "2019-07-11T12:37:22.865373Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_test_csv(path,para=None):\n",
    "    if para==None:\n",
    "        para = open(path[:-4] + \".txt\", \"r\").read()\n",
    "    data_tag = []\n",
    "    with open(path[:-4] + \".csv\", 'w', encoding='utf-8', newline='') as f:\n",
    "        f_csv = csv.writer(f)\n",
    "        if \"zh\" in path:\n",
    "            for line in para.split(\"。\"):\n",
    "                l = len(line)\n",
    "                line = str(line)\n",
    "                #                 tag = [\"O\" for w in range(l)]\n",
    "                data_tag.append([\" \".join([\"O\" for w in line]), \" \".join([w for w in line])])\n",
    "        else:\n",
    "            for line in para.split(\". \"):\n",
    "                l = len(line.split(\" \"))\n",
    "                tag = [\"O\" for _ in range(l)]\n",
    "                data_tag.append([\" \".join(tag), line])\n",
    "        f_csv.writerows(data_tag)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pick title based on tagged results and choose one that best suits length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:47:53.580839Z",
     "start_time": "2019-07-11T12:47:53.565564Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_result(f, preds, title_len, zh):\n",
    "    result = \"\"\n",
    "    max_dis = 32768\n",
    "    best_sentence = \"\"\n",
    "    for sentence, pred in zip(f, preds):\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i] == 'B_MISC':\n",
    "                answer = sentence.bert_tokens[i]\n",
    "                for j in range(i + 1, len(pred)):\n",
    "                    if pred[j] == 'I_MISC':\n",
    "                        answer += \" \" + sentence.bert_tokens[j]\n",
    "                    else:\n",
    "                        break\n",
    "                len_answer = len(answer)\n",
    "                if abs(len_answer - title_len) < max_dis:\n",
    "                    max_dis = abs(len_answer - title_len)\n",
    "                    best_sentence = sentence\n",
    "                    if zh:\n",
    "                        result = \"\".join(answer.split(\" \"))\n",
    "                    else:\n",
    "                        result = answer\n",
    "#     if result != \"\":\n",
    "#         if zh:\n",
    "#             print(\"\".join(best_sentence.bert_tokens))\n",
    "#         else:\n",
    "#             print(\" \".join(best_sentence.bert_tokens))\n",
    "    print(\"@@\" + result + \"@@\",end=' ')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# choose a language and set relative paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:38:28.069473Z",
     "start_time": "2019-07-11T12:38:28.057735Z"
    }
   },
   "outputs": [],
   "source": [
    "path_result = \"/home/lyn/lw/multiling2019/multiling2019_wiki/WikiTrain19/test/MultiLing2019-Summary-2length/result/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:38:28.547501Z",
     "start_time": "2019-07-11T12:38:28.513270Z"
    }
   },
   "outputs": [],
   "source": [
    "path_head = \"/home/lyn/lw/multiling2019/multiling2019_wiki/WikiTrain19/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:38:35.896037Z",
     "start_time": "2019-07-11T12:38:35.885226Z"
    }
   },
   "outputs": [],
   "source": [
    "lan_path = path_head + \"MultiLing2019-Summary-2length/2019.07.06-10.54.47-SentenceVec/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:51:00.430749Z",
     "start_time": "2019-07-11T12:51:00.417094Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_title(test_path, original_path, zh, language):\n",
    "    for article in os.listdir(test_path):\n",
    "        if \"csv\" in article and \"subtitle\" not in article:\n",
    "#             print(article)\n",
    "            tree = ET.ElementTree(file=original_path + article[:-4] + \".xml\")\n",
    "            root = tree.getroot()\n",
    "            title_len = int(root[0].text.lower())\n",
    "#             print(title_len)\n",
    "            dl, f = get_bert_data_loader_for_predict(test_path + article, learner)\n",
    "            preds = learner.predict(dl)\n",
    "            parser = ParseXML_2019()        \n",
    "            parser.parse(original_path + article[:-4] + \".xml\")\n",
    "            parser.entry_node.text = show_result(f, preds, title_len, zh)\n",
    "            parser.tree.write(path_result + language + \"/\" + article[:-4] + \".xml\", encoding=\"utf-8\",xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T12:52:51.361828Z",
     "start_time": "2019-07-11T12:52:51.345400Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_subtitle(test_path, original_path, zh, language):\n",
    "    for file_name in os.listdir(original_path):\n",
    "        if \"xml\" in file_name:\n",
    "            print(file_name)\n",
    "            parser = ParseXML_2019()     \n",
    "            try:\n",
    "                parser.parse(path_result + language + \"/\" + file_name[:-4] + \".xml\")\n",
    "        #         print(len(parser.header_node),len(parser.header_length),len(parser.text))\n",
    "                for length,text,header in zip(parser.header_length, parser.text, parser.header_node):\n",
    "                    tmp_csv_for_subtitle = test_path + str(file_name[:-4]) + \"_subtitle\"\n",
    "                    make_test_csv(tmp_csv_for_subtitle + \".xml\", text) \n",
    "                    try:\n",
    "                        dl, f = get_bert_data_loader_for_predict(tmp_csv_for_subtitle + \".csv\", learner)\n",
    "                    except RuntimeError:\n",
    "                        print(file_name)\n",
    "                    preds = learner.predict(dl)\n",
    "                    header.text = show_result(f, preds, length, zh)\n",
    "                parser.tree.write(path_result + language + \"/\" + file_name[:-4] + \".xml\", encoding=\"utf-8\",xml_declaration=True)\n",
    "            except FileNotFoundError:\n",
    "                print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T13:29:23.526307Z",
     "start_time": "2019-07-11T13:29:12.216323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------ja----------------------------\n",
      "\n",
      "@@下@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@オ@@ @@エ@@ @@##松@@ @@@@ @@@@ @@旧@@ @@@@ @@@@ @@ワ@@ @@@@ @@ス@@ @@@@ @@北@@ @@@@ @@@@ @@@@ 9e833ce5d08c4699e9f31a95f547c99d.xml\n",
      "@@@@ @@@@ @@山@@ @@@@ @@@@ @@ボ@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@海@@ @@@@ @@下@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@工@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@@@ @@国@@ @@@@ @@@@ @@@@ @@@@ 8703a9f6344124436ead15d79e32bc18.xml\n",
      "@@三@@ @@千@@ @@下@@ @@@@ @@@@ "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d348f42f0ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mmake_test_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmake_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmake_subtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-f71eb859cd56>\u001b[0m in \u001b[0;36mmake_subtitle\u001b[0;34m(test_path, original_path, zh, language)\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                     \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_result\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxml_declaration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lw/multiling2019/multiling2019_wiki/ner-bert/modules/train/train.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, dl)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lw/multiling2019/multiling2019_wiki/ner-bert/modules/train/train.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(dl, model, id2label, id2cls)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mlabels_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid2cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lw/multiling2019/multiling2019_wiki/ner-bert/modules/models/bert_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lw/multiling2019/multiling2019_wiki/ner-bert/modules/layers/decoders.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_outputs, input_mask)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lw/multiling2019/multiling2019_wiki/ner-bert/modules/layers/decoders.py\u001b[0m in \u001b[0;36mforward_model\u001b[0;34m(self, encoder_outputs, input_mask)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0maligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maligns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;31m# input, context, aligned encoder hidden, hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;31m# print(hidden[0].shape, context.transpose(0, 1).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for language in os.listdir(lan_path):\n",
    "    if \"txt\" not in language and \"ja\" in language:\n",
    "        print(\"\\n-------------------------\" + language + \"----------------------------\\n\")\n",
    "        test_path = path_head + \"MultiLing2019-Summary-2length/2019.07.06-10.54.47-SentenceVec/\" + language + \"/systems/\"\n",
    "        original_path = path_head + \"WikiTest19/clipped/\" + language + \"/\"\n",
    "        if \"zh\" in test_path or \"ja\" in test_path:\n",
    "            zh = True\n",
    "        else:\n",
    "            zh = False\n",
    "        for idx, f in enumerate(os.listdir(test_path)):\n",
    "            if \"txt\" in f:\n",
    "#                 print(idx, f)\n",
    "                make_test_csv(test_path + f)\n",
    "        make_title(test_path, original_path, zh, language)\n",
    "        make_subtitle(test_path, original_path, zh, language)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T13:27:03.941020Z",
     "start_time": "2019-07-09T13:27:03.905552Z"
    }
   },
   "outputs": [],
   "source": [
    "language = \"zh\"\n",
    "\n",
    "test_path = path_head + \"MultiLing2019-Summary-2length/2019.07.06-10.54.47-SentenceVec/\" + language + \"/systems/\"\n",
    "original_path = path_head + \"WikiTest19/clipped/\" + language + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make test csv for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T13:27:04.815467Z",
     "start_time": "2019-07-09T13:27:04.769681Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, f in enumerate(os.listdir(test_path)):\n",
    "    if \"txt\" in f:\n",
    "        print(idx, f)\n",
    "        make_test_csv(test_path + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show results for title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T13:30:26.374728Z",
     "start_time": "2019-07-09T13:30:24.163834Z"
    }
   },
   "outputs": [],
   "source": [
    "if \"zh\" in test_path:\n",
    "    zh = True\n",
    "else:\n",
    "    zh = False\n",
    "for article in os.listdir(test_path):\n",
    "    if \"csv\" in article and \"subtitle\" not in article:\n",
    "        print(article)\n",
    "        tree = ET.ElementTree(file=original_path + article[:-4] + \".xml\")\n",
    "        root = tree.getroot()\n",
    "        title_len = int(root[0].text.lower())\n",
    "        print(title_len)\n",
    "        dl, f = get_bert_data_loader_for_predict(test_path + article, learner)\n",
    "        preds = learner.predict(dl)\n",
    "        parser = ParseXML_2019()        \n",
    "        parser.parse(original_path + article[:-4] + \".xml\")\n",
    "        parser.entry_node.text = show_result(f, preds, title_len, zh)\n",
    "        parser.tree.write(test_path + article[:-4] + \"_result.xml\", encoding=\"utf-8\",xml_declaration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make test csv for subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T13:30:45.053896Z",
     "start_time": "2019-07-09T13:30:28.728010Z"
    }
   },
   "outputs": [],
   "source": [
    "for file_name in os.listdir(original_path):\n",
    "    if \"xml\" in file_name:\n",
    "        print(file_name)\n",
    "        parser = ParseXML_2019()        \n",
    "        parser.parse(test_path + file_name[:-4] + \"_result.xml\")\n",
    "#         print(len(parser.header_node),len(parser.header_length),len(parser.text))\n",
    "        for length,text,header in zip(parser.header_length, parser.text, parser.header_node):\n",
    "            tmp_csv_for_subtitle = test_path + str(file_name[:-4]) + \"_subtitle\"\n",
    "            make_test_csv(tmp_csv_for_subtitle + \".xml\", text) \n",
    "            dl, f = get_bert_data_loader_for_predict(tmp_csv_for_subtitle + \".csv\", learner)\n",
    "            preds = learner.predict(dl)\n",
    "            header.text = show_result(f, preds, length, zh)\n",
    "        parser.tree.write(test_path + file_name[:-4] + \"_result.xml\", encoding=\"utf-8\",xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
